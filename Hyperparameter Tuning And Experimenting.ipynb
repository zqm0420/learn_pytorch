{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_correct(preds,labels):\n",
    "    return preds.argmax(dim=1).eq(labels).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network,self).__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
    "        self.conv2 = torch.nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5)\n",
    "        \n",
    "        self.fc1 = torch.nn.Linear(in_features=12*4*4, out_features=120)\n",
    "        self.fc2 = torch.nn.Linear(in_features=120, out_features=60)\n",
    "        self.out = torch.nn.Linear(in_features=60, out_features=10)\n",
    "        \n",
    "    def forward(self,t):\n",
    "        # 1. input layer\n",
    "        t = t\n",
    "        # 2. hidden conv layer\n",
    "        t = self.conv1(t)\n",
    "        t = F.relu(t)\n",
    "        t = F.max_pool2d(t,kernel_size=2, stride=2)\n",
    "        \n",
    "        # 3. hidden conv layer 2\n",
    "        t = self.conv2(t)\n",
    "        t = F.relu(t)\n",
    "        t = F.max_pool2d(t,kernel_size=2, stride=2)\n",
    "        \n",
    "        # 4. linear layer1\n",
    "        t = t.reshape(-1,12*4*4)\n",
    "        t = self.fc1(t)\n",
    "        t = F.relu(t)\n",
    "        \n",
    "        # 5. linear layer 2\n",
    "        t = self.fc2(t)\n",
    "        t = F.relu(t)\n",
    "        \n",
    "        # 6. output layer\n",
    "        t = self.out(t)\n",
    "#         t = F.softmax()\n",
    "        \n",
    "        return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = torchvision.datasets.FashionMNIST(\n",
    "    root='./data'\n",
    "    ,train=True\n",
    "    ,download=True\n",
    "    ,transform=transforms.Compose([\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01 10 True\n",
      "0.01 10 False\n",
      "0.01 100 True\n",
      "0.01 100 False\n",
      "0.01 1000 True\n",
      "0.01 1000 False\n",
      "0.001 10 True\n",
      "0.001 10 False\n",
      "0.001 100 True\n",
      "0.001 100 False\n",
      "0.001 1000 True\n",
      "0.001 1000 False\n"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "\n",
    "parameters = dict(\n",
    "    lr = [.01, .001]\n",
    "    ,batch_size = [10, 100, 1000]\n",
    "    ,shuffle = [True, False]\n",
    ")\n",
    "param_values = list(parameters.values())\n",
    "for lr, batch_size, shuffle in product(*param_values):\n",
    "    print(lr, batch_size, shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs: 0 total_loss: 38062.21141083166 total_correct: 45583\n",
      "epochs: 1 total_loss: 32667.050301930867 total_correct: 47880\n",
      "epochs: 2 total_loss: 32007.768761581865 total_correct: 48360\n",
      "epochs: 3 total_loss: 31746.64240897866 total_correct: 48598\n",
      "epochs: 4 total_loss: 32250.7545022259 total_correct: 48318\n",
      "epochs: 5 total_loss: 31581.662222502055 total_correct: 48695\n",
      "epochs: 6 total_loss: 30980.29316665721 total_correct: 48988\n",
      "epochs: 7 total_loss: 31868.901458398905 total_correct: 48721\n",
      "epochs: 8 total_loss: 32853.47199866548 total_correct: 48569\n",
      "epochs: 9 total_loss: 30540.147172547877 total_correct: 49057\n",
      "epochs: 0 total_loss: 36822.03358098632 total_correct: 46693\n",
      "epochs: 1 total_loss: 31436.656772602946 total_correct: 48924\n",
      "epochs: 2 total_loss: 33009.11470523104 total_correct: 48510\n",
      "epochs: 3 total_loss: 32063.661243410315 total_correct: 49115\n",
      "epochs: 4 total_loss: 31011.099695358425 total_correct: 49327\n",
      "epochs: 5 total_loss: 32731.78260494955 total_correct: 48590\n",
      "epochs: 6 total_loss: 33154.403524466325 total_correct: 48373\n",
      "epochs: 7 total_loss: 32490.097658634186 total_correct: 48554\n",
      "epochs: 8 total_loss: 33446.504122829065 total_correct: 48460\n",
      "epochs: 9 total_loss: 32796.48618576408 total_correct: 48607\n",
      "epochs: 0 total_loss: 34464.7424146533 total_correct: 47033\n",
      "epochs: 1 total_loss: 23445.48256844282 total_correct: 51228\n",
      "epochs: 2 total_loss: 21449.718126654625 total_correct: 52019\n",
      "epochs: 3 total_loss: 20166.24255180359 total_correct: 52516\n",
      "epochs: 4 total_loss: 19852.65996605158 total_correct: 52640\n",
      "epochs: 5 total_loss: 19240.75153619051 total_correct: 52885\n",
      "epochs: 6 total_loss: 18845.25877535343 total_correct: 53021\n",
      "epochs: 7 total_loss: 19014.33686763048 total_correct: 52949\n",
      "epochs: 8 total_loss: 18244.833487272263 total_correct: 53266\n",
      "epochs: 9 total_loss: 17798.00281226635 total_correct: 53419\n",
      "epochs: 0 total_loss: 33889.22674655914 total_correct: 46994\n",
      "epochs: 1 total_loss: 22506.863725185394 total_correct: 51667\n",
      "epochs: 2 total_loss: 20723.780524730682 total_correct: 52316\n",
      "epochs: 3 total_loss: 19611.948831379414 total_correct: 52739\n",
      "epochs: 4 total_loss: 18844.243723154068 total_correct: 53027\n",
      "epochs: 5 total_loss: 18824.375102669 total_correct: 52996\n",
      "epochs: 6 total_loss: 18537.756400555372 total_correct: 53108\n",
      "epochs: 7 total_loss: 18107.451501488686 total_correct: 53268\n",
      "epochs: 8 total_loss: 17943.077673763037 total_correct: 53302\n",
      "epochs: 9 total_loss: 17596.305694431067 total_correct: 53473\n",
      "epochs: 0 total_loss: 58740.87107181549 total_correct: 37495\n",
      "epochs: 1 total_loss: 31944.346576929092 total_correct: 47767\n",
      "epochs: 2 total_loss: 26349.60973262787 total_correct: 50361\n",
      "epochs: 3 total_loss: 23190.0751888752 total_correct: 51469\n",
      "epochs: 4 total_loss: 21538.07920217514 total_correct: 51990\n",
      "epochs: 5 total_loss: 20621.83591723442 total_correct: 52370\n",
      "epochs: 6 total_loss: 19246.353268623352 total_correct: 52812\n",
      "epochs: 7 total_loss: 18567.37780570984 total_correct: 53021\n",
      "epochs: 8 total_loss: 17480.15734553337 total_correct: 53500\n",
      "epochs: 9 total_loss: 17668.673664331436 total_correct: 53367\n",
      "epochs: 0 total_loss: 64557.79010057449 total_correct: 35847\n",
      "epochs: 1 total_loss: 32753.715932369232 total_correct: 47079\n",
      "epochs: 2 total_loss: 27496.82280421257 total_correct: 49574\n",
      "epochs: 3 total_loss: 24501.56083703041 total_correct: 50879\n",
      "epochs: 4 total_loss: 22091.631948947906 total_correct: 51709\n",
      "epochs: 5 total_loss: 20500.93874335289 total_correct: 52330\n",
      "epochs: 6 total_loss: 19721.706837415695 total_correct: 52640\n",
      "epochs: 7 total_loss: 18965.372055768967 total_correct: 52938\n",
      "epochs: 8 total_loss: 18265.958726406097 total_correct: 53207\n",
      "epochs: 9 total_loss: 17366.58188700676 total_correct: 53444\n",
      "epochs: 0 total_loss: 34989.00640049949 total_correct: 46734\n",
      "epochs: 1 total_loss: 23003.676443058066 total_correct: 51545\n",
      "epochs: 2 total_loss: 19804.575302852318 total_correct: 52638\n",
      "epochs: 3 total_loss: 17924.408987688366 total_correct: 53325\n",
      "epochs: 4 total_loss: 16811.957950881915 total_correct: 53738\n",
      "epochs: 5 total_loss: 15871.15708921221 total_correct: 53981\n",
      "epochs: 6 total_loss: 15167.95677663642 total_correct: 54246\n",
      "epochs: 7 total_loss: 14414.563319010485 total_correct: 54572\n",
      "epochs: 8 total_loss: 13863.848809900592 total_correct: 54805\n",
      "epochs: 9 total_loss: 13453.148434620816 total_correct: 54913\n",
      "epochs: 0 total_loss: 35202.741430327296 total_correct: 46596\n",
      "epochs: 1 total_loss: 23638.031715375837 total_correct: 51312\n",
      "epochs: 2 total_loss: 20617.619408119936 total_correct: 52371\n",
      "epochs: 3 total_loss: 18888.812024649233 total_correct: 53009\n",
      "epochs: 4 total_loss: 17610.93946598732 total_correct: 53462\n",
      "epochs: 5 total_loss: 16694.465848572145 total_correct: 53763\n",
      "epochs: 6 total_loss: 15914.17686389963 total_correct: 54048\n",
      "epochs: 7 total_loss: 15256.96606318459 total_correct: 54327\n",
      "epochs: 8 total_loss: 14698.689834328397 total_correct: 54490\n",
      "epochs: 9 total_loss: 14198.463827017258 total_correct: 54627\n",
      "epochs: 0 total_loss: 46281.36735856533 total_correct: 42565\n",
      "epochs: 1 total_loss: 29791.74192249775 total_correct: 48969\n",
      "epochs: 2 total_loss: 25462.88085579872 total_correct: 50678\n",
      "epochs: 3 total_loss: 22792.230950295925 total_correct: 51643\n",
      "epochs: 4 total_loss: 21174.11768436432 total_correct: 52210\n",
      "epochs: 5 total_loss: 20108.176538348198 total_correct: 52631\n",
      "epochs: 6 total_loss: 19212.63214945793 total_correct: 52954\n",
      "epochs: 7 total_loss: 18495.195238292217 total_correct: 53167\n",
      "epochs: 8 total_loss: 17907.278767973185 total_correct: 53438\n",
      "epochs: 9 total_loss: 17333.73524621129 total_correct: 53618\n",
      "epochs: 0 total_loss: 44269.802632927895 total_correct: 43447\n",
      "epochs: 1 total_loss: 28510.47452688217 total_correct: 49381\n",
      "epochs: 2 total_loss: 24690.661230683327 total_correct: 51050\n",
      "epochs: 3 total_loss: 22440.79351425171 total_correct: 51841\n",
      "epochs: 4 total_loss: 20732.94598609209 total_correct: 52404\n",
      "epochs: 5 total_loss: 19514.64733183384 total_correct: 52851\n",
      "epochs: 6 total_loss: 18564.5515114069 total_correct: 53205\n",
      "epochs: 7 total_loss: 17770.91161608696 total_correct: 53450\n",
      "epochs: 8 total_loss: 17037.543343007565 total_correct: 53755\n",
      "epochs: 9 total_loss: 16383.198114484549 total_correct: 53967\n",
      "epochs: 0 total_loss: 94889.11616802216 total_correct: 26189\n",
      "epochs: 1 total_loss: 46728.14518213272 total_correct: 42235\n",
      "epochs: 2 total_loss: 39340.329349040985 total_correct: 44688\n",
      "epochs: 3 total_loss: 35782.10777044296 total_correct: 46141\n",
      "epochs: 4 total_loss: 33560.84984540939 total_correct: 47036\n",
      "epochs: 5 total_loss: 31808.651357889175 total_correct: 47736\n",
      "epochs: 6 total_loss: 30494.224697351456 total_correct: 48474\n",
      "epochs: 7 total_loss: 29423.83685708046 total_correct: 49039\n",
      "epochs: 8 total_loss: 28108.38782787323 total_correct: 49720\n",
      "epochs: 9 total_loss: 27080.98316192627 total_correct: 50133\n",
      "epochs: 0 total_loss: 94675.58443546295 total_correct: 27799\n",
      "epochs: 1 total_loss: 47195.93787193298 total_correct: 42220\n",
      "epochs: 2 total_loss: 40496.50728702545 total_correct: 44453\n",
      "epochs: 3 total_loss: 37304.44377660751 total_correct: 45641\n",
      "epochs: 4 total_loss: 35146.47728204727 total_correct: 46564\n",
      "epochs: 5 total_loss: 33402.98876166344 total_correct: 47340\n",
      "epochs: 6 total_loss: 31919.030398130417 total_correct: 48072\n",
      "epochs: 7 total_loss: 30653.489619493484 total_correct: 48651\n",
      "epochs: 8 total_loss: 29592.243671417236 total_correct: 49100\n",
      "epochs: 9 total_loss: 28596.388429403305 total_correct: 49607\n"
     ]
    }
   ],
   "source": [
    "for lr, batch_size, shuffle in product(*param_values):\n",
    "    network = Network()\n",
    "\n",
    "    comment = f' batch_size={batch_size} lr={lr} shuffle={shuffle}'\n",
    "    train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=shuffle)\n",
    "    optimizer = torch.optim.Adam(network.parameters(), lr=lr)\n",
    "\n",
    "\n",
    "    images,labels = next(iter(train_loader))\n",
    "    grid = torchvision.utils.make_grid(images)\n",
    "\n",
    "    tb = SummaryWriter(comment=comment)\n",
    "    tb.add_image('images',grid)\n",
    "    tb.add_graph(network,images)\n",
    "\n",
    "    for epoch in range(10):\n",
    "\n",
    "        total_loss = 0\n",
    "        total_correct = 0\n",
    "\n",
    "        for batch in train_loader:\n",
    "            images,labels = batch\n",
    "            preds = network(images)\n",
    "            loss = F.cross_entropy(preds,labels)   #计算loss\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()    #计算梯度\n",
    "            optimizer.step()   #更新权重\n",
    "\n",
    "            total_loss += loss.item() * images.shape[0]\n",
    "            total_correct += get_num_correct(preds,labels)\n",
    "\n",
    "        tb.add_scalar('Loss', total_loss,epoch)\n",
    "        tb.add_scalar('Number Correct', total_correct,epoch)\n",
    "        tb.add_scalar('Accuracy', total_correct / len(train_set), epoch)\n",
    "\n",
    "        for name, weight in network.named_parameters():\n",
    "            tb.add_histogram(name, weight, epoch)\n",
    "            tb.add_histogram(f'{name}.grad', weight.grad, epoch)\n",
    "\n",
    "        print('epochs:',epoch,'total_loss:',total_loss,'total_correct:',total_correct)\n",
    "\n",
    "    tb.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
